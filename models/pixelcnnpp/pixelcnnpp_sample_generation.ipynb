{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pixelcnnpp_sample_generation.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMc90WW8HsP4TdD6iyTeLL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jFq1UJ0y5HD5"},"outputs":[],"source":["#VM gpu & memory information\n","\n","gpu_info = !nvidia-smi -L\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","\n","# !nvidia-smi --query-gpu=gpu_name,driver_version,memory.total --format=csv\n","\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')\n"]},{"cell_type":"code","source":["%load_ext autoreload\n","%autoreload 2\n","%aimport\n","\n","import torch \n","import numpy as np\n","import torchvision \n","import matplotlib.pyplot as plt"],"metadata":{"id":"yt6FOKo35mLZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# edit according to the number of samples to generate, current script will generate 45k samples as a training data\n","!python generate_sample.py "],"metadata":{"id":"aN1WvfpE5nnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# generated 5000 samples\n","xgen = np.load('./data/valid_gen.npz')\n","sample = torch.from_numpy(xgen['valid_data'])\n","print(sample.shape, type(sample)) # [N, 32,32,3 ]"],"metadata":{"id":"qZM0iD3G5sso"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# visualize 5th sample\n","plt.imshow(sample[5].numpy())"],"metadata":{"id":"HHG3xw6-5xzT"},"execution_count":null,"outputs":[]}]}